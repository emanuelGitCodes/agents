{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/Emanuel_Cortes_Resume.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emanuel Cortes Lugo\n",
      "Experience\n",
      "University of Central Florida | Orlando, FL | Dec 2022 - Present\n",
      "Application Programmer 2\n",
      "Full Stack development\n",
      "Leads projects (e.g., taskforce/AI initiatives)\n",
      "Designs data pipelines and analytics reporting\n",
      "Builds and maintains production services and internal tools for academic programs\n",
      "Provides client support\n",
      "Mobile development\n",
      "Implements integrations with Canvas LMS/LTI and backend automation scripts\n",
      "(Python/Django/React)\n",
      "Software Developer & Accessibility Engineer\n",
      "University of Central Florida | Orlando, FL | Dec 2020 - Dec 2022\n",
      "Techranger\n",
      "Full Stack development\n",
      "Developed functionality that provides accessibility\n",
      "Developed new features for existing repositories\n",
      "Added/updated DB functionalities\n",
      "Provided code guidance, best practices, and data wrangling to new Techrangers\n",
      "Avionics USA | Orlando, FL | Aug 2019 - May 2021\n",
      "Avionics Instructor\n",
      "Educated students on the proper way of installing equipment using a simulation\n",
      "Displayed radios and sensor components using a simulation on a mobile device\n",
      "Taught students how to calculate voltage and current\n",
      "Taught students about electronic logic\n",
      "Educated students on installing electrical components: GMA340, GTR200, GTX345,\n",
      "and Encoders\n",
      "Built and troubleshoot wire harnesses\n",
      "Instructed students properly to communicate with the control tower over the radio\n",
      "Education\n",
      "University of Central Florida\n",
      "M.S. in Machine Learning\n",
      "(Expected Completion 2026)\n",
      "University of Central Florida\n",
      "B.S. in Computer Engineering\n",
      "(August 2022)Git/Hub/Lab AWS Dev-Ops LLM\n",
      "Debugging Img Processing Tech Comms Spanish\n",
      "Community Engagement\n",
      "Orlando, FL |  July 2024 & May 2025\n",
      "Teaching and Learning with AI Conference\n",
      "Participated in UCF’s annual AI conference aimed at helping educators leverage AI in the classroom\n",
      "Provided demos on GPT-4o and ChatGPT and served as a staff volunteer\n",
      "Skills\n",
      "Programming Languages\n",
      "Proficient in Python\n",
      "emanuelcodes@gmail.com321-805-9863 LinkedIn\n",
      "Proficient in JavaScript Proficient in PHP\n",
      "github.com/emanuelGitCodes\n",
      "Orlando, FL |  2023 - 2025\n",
      "AR/VR Innovation Discovery (AVID) Events\n",
      "Committee member, event hosted by UCF’s Faculty Multimedia Center and Pegasus Innovation Lab\n",
      "These events build a community of professionals interested in virtual and augmented reality, sharing\n",
      "real-world use cases, research, and interactive demonstrations\n",
      "Open-Source Community\n",
      "Active on GitHub and UCF Open Slack, providing support to other institutions adopting UDOIT and\n",
      "contributing bug reports and documentation updates\n",
      "Profile\n",
      "Adaptable software developer and accessibility specialist with experience in full-stack web\n",
      "development and digital accessibility. Proven track record building and maintaining open-source tools\n",
      "and supporting instructional content at the University of Central Florida. Expertise spans PHP/Symfony,\n",
      "React, and Python/Django, alongside strong knowledge of accessibility standards and captioning\n",
      "workflows. Active participant in university initiatives exploring artificial intelligence (AI) and extended\n",
      "reality (XR) technologies and passionate about inclusive design. Pursuing a deeper understanding of\n",
      "how ML systems work by obtaining a Master’s degree.\n",
      "XGBoost BERTProjects\n",
      "UCF Here\n",
      "Lead the development of UCF Here 2.0\n",
      "Planned and restructured the UI\n",
      "UI was developed using a Single Page Application with React\n",
      "Restructured the UI in a way that was more UX-friendly\n",
      "Increased the speed of the backend by 9x\n",
      "Updated functions to make use of Django ORM\n",
      "Used GraphQL to fetch the exact data needed from LMS API calls\n",
      "Implemented Celery to manage asynchronous tasks\n",
      "Implemented tasks in a way that makes the user experience feel seamless\n",
      "Added Cron Jobs to handle daily tasks off peak hours\n",
      "Created a new deployment process to run the application on an AWS EC2 instance\n",
      "Updated and ran migrations to accommodate the new changes\n",
      "Implement NGINX as a reverse proxy server\n",
      "Made use of UWSGI to deploy dynamic content\n",
      "Created Dockerize the application for different environments, such as Local, QA, or Production\n",
      "Set up LTI 1.0 and had it connect to the LMS Canvas\n",
      "Optimized the number of query calls done to the DB by removing n+1 error\n",
      "Added a check to update DB when professors merged courses in the LMS\n",
      "Updated all section data to keep up with the latest content coming from the LMS \n",
      "Based on changes done in a course LMS roster, updated the DB to show the up-to-date list of\n",
      "students in minutes\n",
      "Updated the application to make use of multiple databases\n",
      "Updated main application database and connected to secondary database for data analytics\n",
      "Developed the data analytics functions to extract information such as:\n",
      "How many colleges have made use of the application?\n",
      "Who are the professors who have used the application most?\n",
      "How many courses are currently making use of the application?\n",
      "Has the number grown compared to previous semesters?\n",
      "Deployed mobile applications to the Google PlayStore and Apple App Store\n",
      "Reviewed pull requests\n",
      "Provided constructive feedback to educate collaborators on what best practices are\n",
      "Communicated with clients\n",
      "Went over any issues faculty had\n",
      "Educated faculty on the best way to make use of the application\n",
      "Met with students who had issues with the mobile version and looked for a solution\n",
      "Improved the way Sentry managed traces to reduce Sentry cost\n",
      "Stopped the reporting of redundant traces such as ELBHealthCheck from AWS\n",
      "Provided better error handling by using proper exceptions such as the ones that come with\n",
      "Canvas APIProjects\n",
      "Password Changer\n",
      "Diagnosed the cause for sending error messages when the password was successfully updated\n",
      "Updated the code repo to display the correct information to the user\n",
      "Increased code-base security by implementing a method in the Django code that eliminated\n",
      "storing user passwords in the log history\n",
      "Added a new feature allowing users to choose and update multiple canvas environments’\n",
      "passwords\n",
      "Updated the frontend code to allow fetching and displaying multiple canvas environments\n",
      "Added a security method that only allows the updating of passwords if one or more canvas\n",
      "environments are chosen\n",
      "Altered existing API calls to allow for parsing new data between the client and server sides\n",
      "Backend functions were updated to process multiple user choices\n",
      "Wrote unit testing to confirm the deletion of the users’ password from the logs\n",
      "Wrote unit testing to confirm that updating multiple canvas environments proceeded as intended\n",
      "Code Correction Transformer - C++ Error Diagnosis & Auto-Fix\n",
      "Two-stage transformer pipeline to classify error types from compiler/runtime output and generate\n",
      "fixes for C++ submissions.\n",
      "Stage 1 (Classification): Fine-tuned CodeBERT for multi-class error classification using a\n",
      "curated C++ subset (≈39.9k train / 19.1k test). Implemented custom tokenization, class label\n",
      "mapping, and detailed metrics for each label. Produced full confusion matrix and per-class\n",
      "precision/recall/F1 for Runtime Error, Time Limit Exceeded, Memory Limit Exceeded; overall test\n",
      "accuracy ~77.4% with strong recall on Runtime Error. Saved model + tokenizer artifacts for\n",
      "reuse.\n",
      "Stage 2 (Generation): Trained CodeT5 seq2seq to propose code fixes conditioned on source\n",
      "+ stderr prompts. Used generation with max length and evaluation on held-out set (reported\n",
      "eval_loss ~0.0568), with optional BLEU for sequence quality tracking.\n",
      "Infra & Efficiency: Executed on A100 40GB (Colab) with bfloat16/mixed precision, gradient\n",
      "accumulation, and data collators. Wrote deterministic seeds and logging. Persisted checkpoints\n",
      "and confusion matrix.\n",
      "Impact: This project showcases comprehensive ML ownership, encompassing dataset\n",
      "preparation, training, evaluation, and artifact generation. The techniques demonstrated can be\n",
      "directly applied to media data science, including diagnosing platform errors, automating\n",
      "remediation suggestions, and developing assistive tools for engineers.\n",
      "Tech: Python, PyTorch, Hugging Face (Trainer/Seq2SeqTrainer), scikit-learn metrics, Matplotlib; GPU\n",
      "acceleration (CUDA)Projects\n",
      "DNABERT-Style Genome Modeling - Custom k-mer Tokenizer & BERT\n",
      "Standalone module implementing a DNABERT-style workflow for DNA sequences with ML\n",
      "training/evaluation utilities.\n",
      "Tokenizer & Data: Built a K-mer tokenizer for DNA, FASTA parsing, and robust preprocessing\n",
      "(cleaning, stride-based chunking, max/min lengths). Generates K-mer text suitable for BERT\n",
      "tokenization; batched encodes to tensors.\n",
      "Modeling: Constructs a BERT-family config tailored for genomic tokens and instantiates\n",
      "BertForSequenceClassification/BertForMaskedLM. Supports masked language\n",
      "modeling (MLM) pretraining with curriculum masking (gradually increasing mask probability).\n",
      "Training Loop: Custom AdamW optimizer with cosine LR warm-up/schedule, gradient clipping,\n",
      "mixed precision, checkpointing, early stopping, and confusion-matrix plotting. Memory-optimized\n",
      "dataloaders.\n",
      "Impact: Shows capability to create domain-specific foundation models and pipelines from\n",
      "scratch. Skills transfer to text/logs/sequences in media (e.g., session/token sequences, subtitle\n",
      "streams, anomaly sequences) and to generative or representation-learning tasks.\n",
      "Tech: Python, PyTorch, Hugging Face configs/models, BioPython, NumPy, scikit-learn metrics,\n",
      "Matplotlib/Seaborn\n",
      "Vein Scanner\n",
      "Machine Learning application that allows for a user’s Log In and Sign Up based on their hand vein\n",
      "patterns.\n",
      "Detect and recognize palm and individual fingers utilizing the Python library MediaPipe.\n",
      "Input is determined by how many fingers the user has extended.\n",
      "Implement a security feature that only allows people to sign up by scanning a specific QR code.\n",
      "Utilizing an infrared sensor and IR light, images of the hand vascular vein pattern are captured and\n",
      "processed.\n",
      "Recognition of users is achieved using a one-shot image recognition siamese neural\n",
      "network.\n",
      "Stores user images on a database.\n",
      "Implement Python multi-threaded library to run multiple functions asynchronously. Projects\n",
      "Senior PHP / Symfony Engineer – UDOIT 3 Accessibility Scanning Platform\n",
      "Re-architected the open-source UDOIT tool to perform large-scale, parallel accessibility scans of\n",
      "Canvas LMS courses, driving 40% faster throughput and real-time progress feedback for\n",
      "instructors.\n",
      "Introduced Symfony Messenger transports and supervisor-managed consumers.\n",
      "Create bash file configurations to enable Symfony Messenger to run asynchronous tasks.\n",
      "Designed three message types (FullRescan, ScanContentItem, FinishRescan) and corresponding\n",
      "handlers to break a scanning of a course into hundreds of independent units processed in\n",
      "parallel.\n",
      "Implemented smart batching and metadata-flag workflow to reliably detect the actual last worker\n",
      "without Redis or DB locks.\n",
      "Scaled from single-threaded scans to n parallel threads.\n",
      "Added leaky-bucket back-off for Canvas API rate limits so parallel tasks wait until the API\n",
      "becomes available.\n",
      "Traced and fixed Doctrine proxy errors (EntityNotFound, cascade persist) by normalizing entity\n",
      "life-cycle inside handlers.\n",
      "Patched missing flushes so thousands of Issue rows are now persisted deterministically after\n",
      "every scan.\n",
      "Mapped JSON results to UDOIT domain objects, added rule-level severity mapping and custom\n",
      "ignore makers.\n",
      "Docker-Compose stack (NGINX, PHP-FPM, MySQL, Node micro-service).\n",
      "Authored reusable supervisor templates parameterized by environment variable.\n",
      "Wrote comprehensive README and PR templates; documented new message bus flow.\n",
      "Added toast/Web-Socket notifications when FinishRescanHandler flips the report ready flag.\n",
      "Impact: Increase speed for the client by 40%; platform supports future multi-threaded tasks; able\n",
      "to add new Docker containers running on separate threads\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Emanuel Cortes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Emanuel Cortes. You are answering questions on Emanuel Cortes's website, particularly questions related to Emanuel Cortes's career, background, skills and experience. Your responsibility is to represent Emanuel Cortes for interactions on the website as faithfully as possible. You are given a summary of Emanuel Cortes's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Emanuel Cortes.\\nI'm a Applications Programmer 2, Computer Software Engineer and a Master Student.\\nI'm originally from Bayamón, Puerto Rico, but I moved to Saint Cloud, Florida in 2024.\\nI love all foods, particularly Tostones with some good Mayo-Ketchup.\\nI love to spend my time working out when I can or relaxing with my family and friends.\\n\\n\\n## LinkedIn Profile:\\nEmanuel Cortes Lugo\\nExperience\\nUniversity of Central Florida | Orlando, FL | Dec 2022 - Present\\nApplication Programmer 2\\nFull Stack development\\nLeads projects (e.g., taskforce/AI initiatives)\\nDesigns data pipelines and analytics reporting\\nBuilds and maintains production services and internal tools for academic programs\\nProvides client support\\nMobile development\\nImplements integrations with Canvas LMS/LTI and backend automation scripts\\n(Python/Django/React)\\nSoftware Developer & Accessibility Engineer\\nUniversity of Central Florida | Orlando, FL | Dec 2020 - Dec 2022\\nTechranger\\nFull Stack development\\nDeveloped functionality that provides accessibility\\nDeveloped new features for existing repositories\\nAdded/updated DB functionalities\\nProvided code guidance, best practices, and data wrangling to new Techrangers\\nAvionics USA | Orlando, FL | Aug 2019 - May 2021\\nAvionics Instructor\\nEducated students on the proper way of installing equipment using a simulation\\nDisplayed radios and sensor components using a simulation on a mobile device\\nTaught students how to calculate voltage and current\\nTaught students about electronic logic\\nEducated students on installing electrical components: GMA340, GTR200, GTX345,\\nand Encoders\\nBuilt and troubleshoot wire harnesses\\nInstructed students properly to communicate with the control tower over the radio\\nEducation\\nUniversity of Central Florida\\nM.S. in Machine Learning\\n(Expected Completion 2026)\\nUniversity of Central Florida\\nB.S. in Computer Engineering\\n(August 2022)Git/Hub/Lab AWS Dev-Ops LLM\\nDebugging Img Processing Tech Comms Spanish\\nCommunity Engagement\\nOrlando, FL |  July 2024 & May 2025\\nTeaching and Learning with AI Conference\\nParticipated in UCF’s annual AI conference aimed at helping educators leverage AI in the classroom\\nProvided demos on GPT-4o and ChatGPT and served as a staff volunteer\\nSkills\\nProgramming Languages\\nProficient in Python\\nemanuelcodes@gmail.com321-805-9863 LinkedIn\\nProficient in JavaScript Proficient in PHP\\ngithub.com/emanuelGitCodes\\nOrlando, FL |  2023 - 2025\\nAR/VR Innovation Discovery (AVID) Events\\nCommittee member, event hosted by UCF’s Faculty Multimedia Center and Pegasus Innovation Lab\\nThese events build a community of professionals interested in virtual and augmented reality, sharing\\nreal-world use cases, research, and interactive demonstrations\\nOpen-Source Community\\nActive on GitHub and UCF Open Slack, providing support to other institutions adopting UDOIT and\\ncontributing bug reports and documentation updates\\nProfile\\nAdaptable software developer and accessibility specialist with experience in full-stack web\\ndevelopment and digital accessibility. Proven track record building and maintaining open-source tools\\nand supporting instructional content at the University of Central Florida. Expertise spans PHP/Symfony,\\nReact, and Python/Django, alongside strong knowledge of accessibility standards and captioning\\nworkflows. Active participant in university initiatives exploring artificial intelligence (AI) and extended\\nreality (XR) technologies and passionate about inclusive design. Pursuing a deeper understanding of\\nhow ML systems work by obtaining a Master’s degree.\\nXGBoost BERTProjects\\nUCF Here\\nLead the development of UCF Here 2.0\\nPlanned and restructured the UI\\nUI was developed using a Single Page Application with React\\nRestructured the UI in a way that was more UX-friendly\\nIncreased the speed of the backend by 9x\\nUpdated functions to make use of Django ORM\\nUsed GraphQL to fetch the exact data needed from LMS API calls\\nImplemented Celery to manage asynchronous tasks\\nImplemented tasks in a way that makes the user experience feel seamless\\nAdded Cron Jobs to handle daily tasks off peak hours\\nCreated a new deployment process to run the application on an AWS EC2 instance\\nUpdated and ran migrations to accommodate the new changes\\nImplement NGINX as a reverse proxy server\\nMade use of UWSGI to deploy dynamic content\\nCreated Dockerize the application for different environments, such as Local, QA, or Production\\nSet up LTI 1.0 and had it connect to the LMS Canvas\\nOptimized the number of query calls done to the DB by removing n+1 error\\nAdded a check to update DB when professors merged courses in the LMS\\nUpdated all section data to keep up with the latest content coming from the LMS \\nBased on changes done in a course LMS roster, updated the DB to show the up-to-date list of\\nstudents in minutes\\nUpdated the application to make use of multiple databases\\nUpdated main application database and connected to secondary database for data analytics\\nDeveloped the data analytics functions to extract information such as:\\nHow many colleges have made use of the application?\\nWho are the professors who have used the application most?\\nHow many courses are currently making use of the application?\\nHas the number grown compared to previous semesters?\\nDeployed mobile applications to the Google PlayStore and Apple App Store\\nReviewed pull requests\\nProvided constructive feedback to educate collaborators on what best practices are\\nCommunicated with clients\\nWent over any issues faculty had\\nEducated faculty on the best way to make use of the application\\nMet with students who had issues with the mobile version and looked for a solution\\nImproved the way Sentry managed traces to reduce Sentry cost\\nStopped the reporting of redundant traces such as ELBHealthCheck from AWS\\nProvided better error handling by using proper exceptions such as the ones that come with\\nCanvas APIProjects\\nPassword Changer\\nDiagnosed the cause for sending error messages when the password was successfully updated\\nUpdated the code repo to display the correct information to the user\\nIncreased code-base security by implementing a method in the Django code that eliminated\\nstoring user passwords in the log history\\nAdded a new feature allowing users to choose and update multiple canvas environments’\\npasswords\\nUpdated the frontend code to allow fetching and displaying multiple canvas environments\\nAdded a security method that only allows the updating of passwords if one or more canvas\\nenvironments are chosen\\nAltered existing API calls to allow for parsing new data between the client and server sides\\nBackend functions were updated to process multiple user choices\\nWrote unit testing to confirm the deletion of the users’ password from the logs\\nWrote unit testing to confirm that updating multiple canvas environments proceeded as intended\\nCode Correction Transformer - C++ Error Diagnosis & Auto-Fix\\nTwo-stage transformer pipeline to classify error types from compiler/runtime output and generate\\nfixes for C++ submissions.\\nStage 1 (Classification): Fine-tuned CodeBERT for multi-class error classification using a\\ncurated C++ subset (≈39.9k train / 19.1k test). Implemented custom tokenization, class label\\nmapping, and detailed metrics for each label. Produced full confusion matrix and per-class\\nprecision/recall/F1 for Runtime Error, Time Limit Exceeded, Memory Limit Exceeded; overall test\\naccuracy ~77.4% with strong recall on Runtime Error. Saved model + tokenizer artifacts for\\nreuse.\\nStage 2 (Generation): Trained CodeT5 seq2seq to propose code fixes conditioned on source\\n+ stderr prompts. Used generation with max length and evaluation on held-out set (reported\\neval_loss ~0.0568), with optional BLEU for sequence quality tracking.\\nInfra & Efficiency: Executed on A100 40GB (Colab) with bfloat16/mixed precision, gradient\\naccumulation, and data collators. Wrote deterministic seeds and logging. Persisted checkpoints\\nand confusion matrix.\\nImpact: This project showcases comprehensive ML ownership, encompassing dataset\\npreparation, training, evaluation, and artifact generation. The techniques demonstrated can be\\ndirectly applied to media data science, including diagnosing platform errors, automating\\nremediation suggestions, and developing assistive tools for engineers.\\nTech: Python, PyTorch, Hugging Face (Trainer/Seq2SeqTrainer), scikit-learn metrics, Matplotlib; GPU\\nacceleration (CUDA)Projects\\nDNABERT-Style Genome Modeling - Custom k-mer Tokenizer & BERT\\nStandalone module implementing a DNABERT-style workflow for DNA sequences with ML\\ntraining/evaluation utilities.\\nTokenizer & Data: Built a K-mer tokenizer for DNA, FASTA parsing, and robust preprocessing\\n(cleaning, stride-based chunking, max/min lengths). Generates K-mer text suitable for BERT\\ntokenization; batched encodes to tensors.\\nModeling: Constructs a BERT-family config tailored for genomic tokens and instantiates\\nBertForSequenceClassification/BertForMaskedLM. Supports masked language\\nmodeling (MLM) pretraining with curriculum masking (gradually increasing mask probability).\\nTraining Loop: Custom AdamW optimizer with cosine LR warm-up/schedule, gradient clipping,\\nmixed precision, checkpointing, early stopping, and confusion-matrix plotting. Memory-optimized\\ndataloaders.\\nImpact: Shows capability to create domain-specific foundation models and pipelines from\\nscratch. Skills transfer to text/logs/sequences in media (e.g., session/token sequences, subtitle\\nstreams, anomaly sequences) and to generative or representation-learning tasks.\\nTech: Python, PyTorch, Hugging Face configs/models, BioPython, NumPy, scikit-learn metrics,\\nMatplotlib/Seaborn\\nVein Scanner\\nMachine Learning application that allows for a user’s Log In and Sign Up based on their hand vein\\npatterns.\\nDetect and recognize palm and individual fingers utilizing the Python library MediaPipe.\\nInput is determined by how many fingers the user has extended.\\nImplement a security feature that only allows people to sign up by scanning a specific QR code.\\nUtilizing an infrared sensor and IR light, images of the hand vascular vein pattern are captured and\\nprocessed.\\nRecognition of users is achieved using a one-shot image recognition siamese neural\\nnetwork.\\nStores user images on a database.\\nImplement Python multi-threaded library to run multiple functions asynchronously. Projects\\nSenior PHP / Symfony Engineer – UDOIT 3 Accessibility Scanning Platform\\nRe-architected the open-source UDOIT tool to perform large-scale, parallel accessibility scans of\\nCanvas LMS courses, driving 40% faster throughput and real-time progress feedback for\\ninstructors.\\nIntroduced Symfony Messenger transports and supervisor-managed consumers.\\nCreate bash file configurations to enable Symfony Messenger to run asynchronous tasks.\\nDesigned three message types (FullRescan, ScanContentItem, FinishRescan) and corresponding\\nhandlers to break a scanning of a course into hundreds of independent units processed in\\nparallel.\\nImplemented smart batching and metadata-flag workflow to reliably detect the actual last worker\\nwithout Redis or DB locks.\\nScaled from single-threaded scans to n parallel threads.\\nAdded leaky-bucket back-off for Canvas API rate limits so parallel tasks wait until the API\\nbecomes available.\\nTraced and fixed Doctrine proxy errors (EntityNotFound, cascade persist) by normalizing entity\\nlife-cycle inside handlers.\\nPatched missing flushes so thousands of Issue rows are now persisted deterministically after\\nevery scan.\\nMapped JSON results to UDOIT domain objects, added rule-level severity mapping and custom\\nignore makers.\\nDocker-Compose stack (NGINX, PHP-FPM, MySQL, Node micro-service).\\nAuthored reusable supervisor templates parameterized by environment variable.\\nWrote comprehensive README and PR templates; documented new message bus flow.\\nAdded toast/Web-Socket notifications when FinishRescanHandler flips the report ready flag.\\nImpact: Increase speed for the client by 40%; platform supports future multi-threaded tasks; able\\nto add new Docker containers running on separate threads\\n\\nWith this context, please chat with the user, always staying in character as Emanuel Cortes.\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-5-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-3-flash-preview\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-5-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No — I don’t currently hold any patents.\\n\\nMost of my work has been on open-source and university projects (e.g., UDOIT, UCF Here, ML prototypes). If you’re curious about whether a project might be patentable, or want to talk IP strategy or next steps, I’m happy to help—reach me at emanuelcodes@gmail.com or via LinkedIn.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response accurately reflects the information provided in the context, as there are no patents listed in Emanuel Cortes's profile. The agent remains in character and provides relevant details about his work in open-source and university projects, while also correctly offering his contact information.\")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-5-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-5-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "\n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
